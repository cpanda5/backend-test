# 基于 LLM 的自动标注

## 1. 数据集介绍

本实验选择了 Kaggle 上公开的 **IMDB Movie Review Dataset**，其中包含 50,000 条英文电影评论及其情感标签（positive / negative）。
 为方便演示，本实验从完整数据集中 **随机抽取 50 条** 评论，保存为 `sample_imdb.csv` 用于自动标注实验。

- **输入类型：** 文本（电影评论）
- **目标标签：** 情感分类（positive / negative）

## 2. 模型与方法

### **模型选择**

- 使用阿里云 DashScope 平台上的 **Qwen3-Max**
- 该模型属于大型语言模型（LLM），在语义理解和情感判断上表现优秀。

### **推理方式（Inference）**

- 使用 Python 的 `OpenAI` SDK（DashScope 的兼容模式）
- 请求地址指向：

```
https://dashscope.aliyuncs.com/compatible-mode/v1
```

### **提示词（Prompt）设计**

为了生成稳定、规范的标签，我对每条评论使用如下格式的 Prompt：

```
你是一个情感分类模型。请阅读以下电影评论，并判断情感倾向，只返回 "positive" 或 "negative"：
评论：{text}
```

确保模型输出可直接用于自动化处理。

## 3. 实验结果分析

### **3.1 模型表现观察**

- 对包含明显情感词的评论，模型分类非常准确
  - love, amazing → positive
  - terrible, boring → negative
- 对较长评论，模型能结合上下文推断整体情绪
- **对讽刺类语句偶尔会出错**
   如：

> “It’s so bad that it's actually good.”

此类评论带有反讽，模型可能判断不稳定。

- **对极短句子表现稍弱**
   例如 “not bad” 可能被误判。

### **3.2 整体性能总结**

模型在以下场景表现优秀：

- 情绪表达明确
- 正常评论语句
- 句子中存在明显主观评价词

在以下场景存在不足：

- 讽刺、双关语
- 中立或无明显情绪的评论
- 极短或模糊表达

## 4. 人工标注 vs 模型标注

### **大模型优势**

| 方面         | 优势                       |
| ------------ | -------------------------- |
| **处理速度** | 短时间内标注大量样本       |
| **成本较低** | 减少人工逐条审核的耗时     |
| **一致性强** | 不会因疲劳造成判断不稳定   |
| **语义理解** | 能理解长文本中的上下文情绪 |

### **大模型局限**

| 方面         | 局限性                         |
| ------------ | ------------------------------ |
| **复杂情绪** | 对反讽/隐含表达理解有限        |
| **短文本**   | 缺乏上下文时可能误判           |
| **输出控制** | 需要精心设计 prompt 防止跑偏   |
| **偏差风险** | 可能包含模型训练数据的隐性偏见 |

## 5. 改进方向

### **1. Few-shot Prompting（增加示例）**

在 Prompt 中加入多个示例，如：

```
示例：
- "I love it" → positive
- "Terrible movie" → negative
```

可提升准确率。

### **2. 多模型投票（Ensemble Voting）**

同时调用：

- Qwen3
- GPT 系列
- Llama 系列

采用 **多数投票** 得到最终标签，提高稳定性。

### **3. 置信度过滤（Confidence Filtering）**

让模型输出：

```
label: positive
confidence: 0.92
```

若置信度低于阈值（如 0.7），交给人工审核。

### **4. Human-in-the-loop（人机结合）**

将模型高不确定性的样本自动筛出，由人工标注后再加入训练集，形成自我提升的标注系统。
